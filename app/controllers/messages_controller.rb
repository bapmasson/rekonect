class MessagesController < ApplicationController
  before_action :authenticate_user!

  # cette route ne sera pas utilisÃ©e (on utilisera pages#dashboard) mais je l'ai mise pour pouvoir se logger!
  def index
      @messages = policy_scope(Message)
  end

  def new
    @message = Message.new
    authorize @message
  end

  # Route pour rÃ©pondre Ã  un message en attente de rÃ©ponse
  # Elle permet de gÃ©nÃ©rer une suggestion de rÃ©ponse via l'API OpenAI et d'afficher un rÃ©sumÃ© des derniers Ã©changes
  # entre l'utilisateur et le contact du message.
  def reply
    @message = Message.find(params[:id])
    authorize @message

    # je recupere les 3 derniers msg avec ce contact, du plus rÃ©cent au plus ancien
     @history_messages = current_user.messages
    .where(contact_id: @message.contact_id)
    .where.not(id: @message.id)
    .order(created_at: :desc)
    .limit(3)
    .where(status: :sent)

    last_messages = current_user.messages.where(contact_id: @message.contact_id).order(updated_at: :desc).last(3)
    @summary = message_summary(last_messages)
    ai_suggestion(@message, @summary) if @message.ai_draft.blank? && @message.status != "draft_by_ai"
  end

  # Route pour "rekonecter" un contact, c'est-Ã -dire relancer la conversation avec une suggestion de rÃ©ponse
  # Elle gÃ©nÃ¨re une suggestion de rÃ©ponse basÃ©e sur les derniers messages Ã©changÃ©s avec le contact.
  # Elle affiche Ã©galement un rÃ©sumÃ© des derniers Ã©changes pour aider l'utilisateur Ã  se remÃ©morer le contexte.
  def rekonect
    @message = Message.find(params[:id])
    authorize @message
    last_messages = current_user.messages.where(contact_id: @message.contact_id).order(updated_at: :desc).last(3)
    @summary = message_summary(last_messages)
    @new_message = Message.new(contact: @message.contact, user: current_user)
    rekonect_suggestion(@new_message, @summary)
  end

  def create
    @message = current_user.messages.build(message_params)
    authorize @message
    if @message.save
      redirect_to messages_path, notice: "Message envoyÃ© avec succÃ¨s."
    else
      render :new, status: :unprocessable_entity
    end
  end

  def awaiting_answer
    @messages = current_user.messages.where(status: :draft_by_ai)
    authorize @messages
  end

  def show
    @message = Message.find(params[:id])
    authorize @message
  end

  def edit
    @message = Message.find(params[:id])
    authorize @message
  end

  def dismiss_suggestion
    @message = current_user.messages.find(params[:id])
    authorize @message
    @message.update(dismissed: true)
    redirect_to messages_path # <-- redirige vers la liste des messages
  end

  def update
    @message = Message.find(params[:id])
    authorize @message

    if @message.update(user_answer: params[:message][:user_answer], status: :sent, sent_at: Time.current)
      redirect_to dashboard_path, notice: "Bravo, tu tâ€™es Rekonect avec succÃ¨sâ€¯! ðŸš€"
    else
      render :edit, status: :unprocessable_entity
    end
  end

  def send_message
    @message = Message.find(params[:id])
    authorize @message

    # copie la suggestion de l'IA dans uiser_answer
    if @message.update(user_answer: @message.ai_draft, status: :sent, sent_at: Date.current)
      redirect_to dashboard_path, notice: "RÃ©ponse envoyÃ©e avec succÃ¨s."
    else
      redirect_to reply_message_path(@message), alert: "Erreur lors de lâ€™envoi de la rÃ©ponse."
    end
  end

  private

  def message_params
    params.require(:message).permit(:content, :contact_id)
  end

  def message_summary(messages)
    cache_key = "message_summary_#{messages.map(&:id).join('_')}"
    summary = Rails.cache.read(cache_key)
    return summary if summary.present?

    # Utilise l'API OpenAI pour gÃ©nÃ©rer un rÃ©sumÃ© des derniers messages
    client = OpenAI::Client.new
    chatgpt_response = client.chat(
      parameters: {
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: "You are a helpful assistant that summarizes conversations." },
          {
            role: "user",
            content:
              "Make a very short recap (80 words max) in French of each interaction between " \
              "#{messages.first&.contact&.name} and the user #{messages.first&.user&.first_name}. " \
              "Speak directly to the user : " \
              "#{messages.map { |m| "message de #{m.contact.name}: #{m.content}#{m.user_answer.present? ? ", rÃ©ponse utilisateur: #{m.user_answer}" : ""}" }.join(", ")}"
          }
        ]
      }
    )
    summary = chatgpt_response["choices"][0]["message"]["content"] if chatgpt_response && chatgpt_response["choices"].any?
    summary ||= "Unable to generate summary at this time."
    Rails.cache.write(cache_key, summary, expires_in: 12.hours)
    summary
  rescue StandardError => e
    Rails.logger.error("OpenAI API error: #{e.message}")
    "Unable to generate summary at this time."
  end

  def ai_suggestion(message, summary)
    # Utilise l'API OpenAI pour gÃ©nÃ©rer une suggestion de rÃ©ponse
    client = OpenAI::Client.new
    chatgpt_response = client.chat(
      parameters: {
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: "You are a helpful assistant that generates message replies." },
          { role: "user", content: "This is the background of the conversation: #{summary}. This is the last message you received : #{message.content}. Generate in French a warmful reply of 50 words max to this last message without repeating the summary as it is meant only for you and not for being in the reply." }
        ]
      }
    )
    ai_suggestion = chatgpt_response["choices"][0]["message"]["content"] if chatgpt_response && chatgpt_response["choices"].any?
    message.update!(ai_draft: ai_suggestion, status: :draft_by_ai) if ai_suggestion.present?
    rescue StandardError => e
      Rails.logger.error("OpenAI API error: #{e.message}")
      "Unable to generate suggestion at this time."
  end

  def rekonect_suggestion(message, summary)
    # Utilise l'API OpenAI pour gÃ©nÃ©rer une suggestion de relance
    client = OpenAI::Client.new
    chatgpt_response = client.chat(
      parameters: {
        model: "gpt-4o-mini",
        messages: [
          { role: "system", content: "You are a helpful assistant that generates messages." },
          { role: "user", content: "It has been a long time since you last wrote to #{message.contact.name}. This is the background of the conversation: #{summary}. Generate in French a warmful message of 50 words max to recreate a conversation with this contact without repeating the summary as it is meant only for you and not for being in the reply." }
        ]
      }
    )
    ai_suggestion = chatgpt_response["choices"][0]["message"]["content"] if chatgpt_response && chatgpt_response["choices"].any?
    message.update!(ai_draft: ai_suggestion, status: :draft_by_ai) if ai_suggestion.present?
    rescue StandardError => e
      Rails.logger.error("OpenAI API error: #{e.message}")
      "Unable to generate suggestion at this time."
  end
end
